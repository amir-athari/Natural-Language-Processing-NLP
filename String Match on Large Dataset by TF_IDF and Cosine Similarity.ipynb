{
 "cells": [
  {
   "source": [
    "# String Matching using NLP TF_IDF on Large Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## The goal here is to find a last name match of a query list of 2000 names in a list of 1.4 million lookup name list. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import plot, xlabel, ylabel\n",
    "%matplotlib inline\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.patches import PathPatch\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import matplotlib.cm as cm\n",
    "from IPython.core.display import display\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "from numpy.random import seed\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "import time\n",
    "import glob\n",
    "import pickle\n",
    "import spacy\n",
    "import re\n",
    "import pyodbc\n",
    "import sqlalchemy as sal\n",
    "from sklearn.preprocessing import normalize \n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from scipy.stats import bartlett\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import normalize \n",
    "from scipy.stats import jarque_bera\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import normaltest\n",
    "import scipy.stats as stats\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import zscore\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score #\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import xlsxwriter\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, \\\n",
    "    adjusted_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.metrics import silhouette_samples,  silhouette_score\n",
    "from sklearn.metrics.cluster import contingency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "from random import sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100) \n",
    "pd.set_option('display.max_colwidth', -1) "
   ]
  },
  {
   "source": [
    "## Import lookup dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1087036, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Import lookup data\n",
    "import_path = \"D:\\\\dev_data\\\\re\\\\hcad\"\n",
    "owner_cols = ['ACCOUNT', 'MAILTO']\n",
    "file_name2 = 'ss_owners.csv'\n",
    "file2 = import_path+\"\\\\\"+ file_name2\n",
    "l1 = pd.read_csv(file2,  dtype= str, encoding = \"ISO-8859-1\", names=owner_cols, skiprows=1)\n",
    "l1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         ACCOUNT                  MAILTO\n",
       "0  0032180000021  SANTOS DOLORES ST JOHN\n",
       "1  0032180000022  GRIMALDO ROSIE        \n",
       "2  0032180000023  GARCIA ANTONIO        "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0032180000021</td>\n      <td>SANTOS DOLORES ST JOHN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0032180000022</td>\n      <td>GRIMALDO ROSIE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0032180000023</td>\n      <td>GARCIA ANTONIO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "l1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'\"','',text)\n",
    "    text = re.sub(r'&','',text)\n",
    "    text = re.sub(r'','',text)\n",
    "    ext = re.sub(\"[\\[].*?[\\]];\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "source": [
    "## Preprocess lookup dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = l1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['santos dolores st john', 'grimaldo rosie', 'garcia antonio']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Convert column of names to string and clean\n",
    "l = l2['MAILTO'].tolist() \n",
    "l=['missing' if x is np.nan else x for x in l]\n",
    "s = '||||'.join(l).lower()\n",
    "sc = text_cleaner(s)\n",
    "#sc[:10]\n",
    "names = [str(x) for x in sc.split('||||') if x]\n",
    "names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           MAILTO_cleaned\n",
       "0  santos dolores st john\n",
       "1  grimaldo rosie        \n",
       "2  garcia antonio        "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAILTO_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>santos dolores st john</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>grimaldo rosie</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>garcia antonio</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "l3 = pd.DataFrame(names, index=l2.index, columns=['MAILTO_cleaned'])\n",
    "l3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1087036, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Combine original df with cleaned names\n",
    "l4 = pd.concat([l2, l3], axis=1)\n",
    "l4['source'] = 'lookup' # Add this so can identify the array later\n",
    "l4['de_prop_given'] = '' # Placeholder for future use\n",
    "l4['id'] = '' # So to match with columns from pro dateset\n",
    "\n",
    "l4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         ACCOUNT                  MAILTO          MAILTO_cleaned  source  \\\n",
       "0  0032180000021  SANTOS DOLORES ST JOHN  santos dolores st john  lookup   \n",
       "1  0032180000022  GRIMALDO ROSIE          grimaldo rosie          lookup   \n",
       "2  0032180000023  GARCIA ANTONIO          garcia antonio          lookup   \n",
       "\n",
       "  de_prop_given id  \n",
       "0                   \n",
       "1                   \n",
       "2                   "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0032180000021</td>\n      <td>SANTOS DOLORES ST JOHN</td>\n      <td>santos dolores st john</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0032180000022</td>\n      <td>GRIMALDO ROSIE</td>\n      <td>grimaldo rosie</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0032180000023</td>\n      <td>GARCIA ANTONIO</td>\n      <td>garcia antonio</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "l4.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1087036, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "l4 = l4.drop_duplicates(subset='ACCOUNT', keep=\"last\")\n",
    "l4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "68266"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Tag commercial names by regex pattern\n",
    "def find_pat(text):\n",
    "    if re.search(r\" llc|current owner|  inc| lc| ltd| lp| churchcorp| company|city of houston|\\\n",
    "        county of harris|state of texas| company| harris county|harris county|county of harris|\\\n",
    "            texas department| city of katy|parcel\", text):\n",
    "        return 1\n",
    "    return   0\n",
    "# Apply the function\n",
    "l4['non_person'] = l4['MAILTO_cleaned'].apply(find_pat)\n",
    "# Number of commercial entries\n",
    "l4['non_person'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1018770, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Drop commercial entries\n",
    "l4 = l4.drop(l4[l4.non_person ==1].index)\n",
    "l4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Add addresses with the word estate in them\n",
    "all_l_names = l4['MAILTO_cleaned'].tolist()\n",
    "r = re.compile(\"estate\")\n",
    "newlist = list(filter(r.match, all_l_names))\n",
    "estate_mask = [i in newlist for i in all_l_names]\n",
    "l4['estate_mask'] = estate_mask\n",
    "l4['estate_mask'] = l4['estate_mask']*1\n",
    "l4['estate_mask'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last name\n",
    "l4['l_name'] = l4['MAILTO_cleaned'].str.extract('^([\\w\\-]+)', expand=True)\n",
    "l4 = l4[~l4['l_name'].isnull()] # Filter away those names that start with digits\n",
    "# Drop extra columns\n",
    "l4 = l4.drop(['MAILTO', 'non_person'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               ACCOUNT              MAILTO_cleaned  source de_prop_given id  \\\n",
       "466446   1071560000012  watkins richard m patricia  lookup                    \n",
       "975247   1297510010009  bolden mary                 lookup                    \n",
       "866314   1248730010010  gonzalez jacqueline g       lookup                    \n",
       "553650   1065240000019  jones april m joseph r      lookup                    \n",
       "1021355  1354430010030  christopher frances         lookup                    \n",
       "\n",
       "         estate_mask       l_name  \n",
       "466446   0            watkins      \n",
       "975247   0            bolden       \n",
       "866314   0            gonzalez     \n",
       "553650   0            jones        \n",
       "1021355  0            christopher  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>id</th>\n      <th>estate_mask</th>\n      <th>l_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>466446</th>\n      <td>1071560000012</td>\n      <td>watkins richard m patricia</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>watkins</td>\n    </tr>\n    <tr>\n      <th>975247</th>\n      <td>1297510010009</td>\n      <td>bolden mary</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>bolden</td>\n    </tr>\n    <tr>\n      <th>866314</th>\n      <td>1248730010010</td>\n      <td>gonzalez jacqueline g</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>gonzalez</td>\n    </tr>\n    <tr>\n      <th>553650</th>\n      <td>1065240000019</td>\n      <td>jones april m joseph r</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>jones</td>\n    </tr>\n    <tr>\n      <th>1021355</th>\n      <td>1354430010030</td>\n      <td>christopher frances</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>christopher</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "l4.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify single letter initials in the name so the get picked by in n-gram vectorization\n",
    "\n",
    "def fix_middle_initial(name):\n",
    "    namel = []\n",
    "    namel = list(name.split(' '))\n",
    "    namel_count = []\n",
    "    namel_count = [len(i) for i in namel]\n",
    "    for i, letter_count in enumerate(namel_count):\n",
    "        if letter_count ==1:\n",
    "            namel[i] = namel[i] * 3\n",
    "        else: continue\n",
    "    return ' '.join(namel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "l4['MAILTO_cleaned2'] = l4['MAILTO_cleaned'].apply(fix_middle_initial)"
   ]
  },
  {
   "source": [
    "# Import query data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5033, 43)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "path = \"D:\\\\dev_data\\\\re\\\\pro\\\\fls\\\\monthly_download\"\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0 , dtype = str)\n",
    "    li.append(df)\n",
    "q1 = pd.concat(li, axis=0, ignore_index=True)\n",
    "q1['ones'] = 1\n",
    "q1 = q1.fillna(0)\n",
    "q1 = q1.astype(str)\n",
    "q1.shape"
   ]
  },
  {
   "source": [
    "## Preprocess querry dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  FLS_DOWNL_DATE DOWNL_SOURCE DOWNL_COUNTY DOCK_NUM               DE_KEY  \\\n",
       "0  22-Dec-20      FLS          HARRIS       490628   490628_DE_JODZIO      \n",
       "1  22-Dec-20      FLS          HARRIS       490639   490639_DE_BOURGEOIS   \n",
       "\n",
       "            DE_NAME DE_FIRST_NAME DE_MIDDLE_NAME DE_LAST_NAME  \\\n",
       "0  DAVID W JODZIO    DAVID         W              JODZIO        \n",
       "1  LOUISE BOURGEOIS  LOUISE        0              BOURGEOIS     \n",
       "\n",
       "           DE_STR_ADD       DE_CITY_ZIP  DE_CITY DE_STATE DE_ZIP DE_KEYMAP  \\\n",
       "0  12719 CORNING DR    HOUSTON TX 77089  HOUSTON  TX       77089  616D       \n",
       "1  9723 SPRINGMONT DR  HOUSTON TX 77080  HOUSTON  TX       77080  450K       \n",
       "\n",
       "  DE_PROP_VAL DE_BR_SQF DE_YR_BUILD                DE_LEGAL_ADD  \\\n",
       "0  $161735     3/1313    1973        LT 30 BLK 9 SCARSDALE 2      \n",
       "1  $206326     3/1800    1971        LT 26 BLK 5 KEMPWOOD NORTH   \n",
       "\n",
       "                EX_KEY             EX_NAME EX_FIRST_NAME EX_MIDDLE_NAME  \\\n",
       "0  490628_EX_JODZIO     HEATHER E JODZIO    HEATHER       E               \n",
       "1  490639_EX_BOURGEOIS  DONALD A BOURGEOIS  DONALD        A               \n",
       "\n",
       "  EX_LAST_NAME          EX_STR_ADD       EX_CITY_ZIP  EX_CITY EX_STATE EX_ZIP  \\\n",
       "0  JODZIO       12719 CORNING DR    HOUSTON TX 77089  HOUSTON  TX       77089   \n",
       "1  BOURGEOIS    9723 SPRINGMONT DR  HOUSTON TX 77080  HOUSTON  TX       77080   \n",
       "\n",
       "  DOCK_FILE_DATE DOCK_FILM             ATT_KEY           ATT_NAME  \\\n",
       "0  12/17/2020     0         490628_ATT_LEWIS    POLLY LEWIS         \n",
       "1  12/17/2020     0         490639_ATT_CORDELL  CHRISTINE CORDELL   \n",
       "\n",
       "  ATT_FIRST_NAME ATT_MIDDLE_NAME ATT_LAST_NAME                       ATT_ADD  \\\n",
       "0  POLLY          0               LEWIS         16055 SPACE CENTER BLVD #190   \n",
       "1  CHRISTINE      0               CORDELL       9800 NW FRWY STE 216           \n",
       "\n",
       "       ATT_CITY_ZIP ATT_CITY ATT_STATE ATT_ZIP LIST_NAME ones  \n",
       "0  HOUSTON TX 77062  HOUSTON  TX        77062   List1     1    \n",
       "1  HOUSTON TX 77092  HOUSTON  TX        77092   List1     1    "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FLS_DOWNL_DATE</th>\n      <th>DOWNL_SOURCE</th>\n      <th>DOWNL_COUNTY</th>\n      <th>DOCK_NUM</th>\n      <th>DE_KEY</th>\n      <th>DE_NAME</th>\n      <th>DE_FIRST_NAME</th>\n      <th>DE_MIDDLE_NAME</th>\n      <th>DE_LAST_NAME</th>\n      <th>DE_STR_ADD</th>\n      <th>DE_CITY_ZIP</th>\n      <th>DE_CITY</th>\n      <th>DE_STATE</th>\n      <th>DE_ZIP</th>\n      <th>DE_KEYMAP</th>\n      <th>DE_PROP_VAL</th>\n      <th>DE_BR_SQF</th>\n      <th>DE_YR_BUILD</th>\n      <th>DE_LEGAL_ADD</th>\n      <th>EX_KEY</th>\n      <th>EX_NAME</th>\n      <th>EX_FIRST_NAME</th>\n      <th>EX_MIDDLE_NAME</th>\n      <th>EX_LAST_NAME</th>\n      <th>EX_STR_ADD</th>\n      <th>EX_CITY_ZIP</th>\n      <th>EX_CITY</th>\n      <th>EX_STATE</th>\n      <th>EX_ZIP</th>\n      <th>DOCK_FILE_DATE</th>\n      <th>DOCK_FILM</th>\n      <th>ATT_KEY</th>\n      <th>ATT_NAME</th>\n      <th>ATT_FIRST_NAME</th>\n      <th>ATT_MIDDLE_NAME</th>\n      <th>ATT_LAST_NAME</th>\n      <th>ATT_ADD</th>\n      <th>ATT_CITY_ZIP</th>\n      <th>ATT_CITY</th>\n      <th>ATT_STATE</th>\n      <th>ATT_ZIP</th>\n      <th>LIST_NAME</th>\n      <th>ones</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22-Dec-20</td>\n      <td>FLS</td>\n      <td>HARRIS</td>\n      <td>490628</td>\n      <td>490628_DE_JODZIO</td>\n      <td>DAVID W JODZIO</td>\n      <td>DAVID</td>\n      <td>W</td>\n      <td>JODZIO</td>\n      <td>12719 CORNING DR</td>\n      <td>HOUSTON TX 77089</td>\n      <td>HOUSTON</td>\n      <td>TX</td>\n      <td>77089</td>\n      <td>616D</td>\n      <td>$161735</td>\n      <td>3/1313</td>\n      <td>1973</td>\n      <td>LT 30 BLK 9 SCARSDALE 2</td>\n      <td>490628_EX_JODZIO</td>\n      <td>HEATHER E JODZIO</td>\n      <td>HEATHER</td>\n      <td>E</td>\n      <td>JODZIO</td>\n      <td>12719 CORNING DR</td>\n      <td>HOUSTON TX 77089</td>\n      <td>HOUSTON</td>\n      <td>TX</td>\n      <td>77089</td>\n      <td>12/17/2020</td>\n      <td>0</td>\n      <td>490628_ATT_LEWIS</td>\n      <td>POLLY LEWIS</td>\n      <td>POLLY</td>\n      <td>0</td>\n      <td>LEWIS</td>\n      <td>16055 SPACE CENTER BLVD #190</td>\n      <td>HOUSTON TX 77062</td>\n      <td>HOUSTON</td>\n      <td>TX</td>\n      <td>77062</td>\n      <td>List1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22-Dec-20</td>\n      <td>FLS</td>\n      <td>HARRIS</td>\n      <td>490639</td>\n      <td>490639_DE_BOURGEOIS</td>\n      <td>LOUISE BOURGEOIS</td>\n      <td>LOUISE</td>\n      <td>0</td>\n      <td>BOURGEOIS</td>\n      <td>9723 SPRINGMONT DR</td>\n      <td>HOUSTON TX 77080</td>\n      <td>HOUSTON</td>\n      <td>TX</td>\n      <td>77080</td>\n      <td>450K</td>\n      <td>$206326</td>\n      <td>3/1800</td>\n      <td>1971</td>\n      <td>LT 26 BLK 5 KEMPWOOD NORTH</td>\n      <td>490639_EX_BOURGEOIS</td>\n      <td>DONALD A BOURGEOIS</td>\n      <td>DONALD</td>\n      <td>A</td>\n      <td>BOURGEOIS</td>\n      <td>9723 SPRINGMONT DR</td>\n      <td>HOUSTON TX 77080</td>\n      <td>HOUSTON</td>\n      <td>TX</td>\n      <td>77080</td>\n      <td>12/17/2020</td>\n      <td>0</td>\n      <td>490639_ATT_CORDELL</td>\n      <td>CHRISTINE CORDELL</td>\n      <td>CHRISTINE</td>\n      <td>0</td>\n      <td>CORDELL</td>\n      <td>9800 NW FRWY STE 216</td>\n      <td>HOUSTON TX 77092</td>\n      <td>HOUSTON</td>\n      <td>TX</td>\n      <td>77092</td>\n      <td>List1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "q1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2432, 43)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Remove duplicate cases\n",
    "q2 = q1.drop_duplicates(subset='DE_KEY', keep=\"first\")\n",
    "q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2338, 43)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Remove duplicated EX SITE ADD\n",
    "q2 = q2.drop_duplicates(subset='EX_STR_ADD', keep=\"first\")\n",
    "q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert full date but different format\n",
    "q2['FLS_DOWNL_DATE'] = pd.to_datetime(q2['FLS_DOWNL_DATE'])\n",
    "q2['DOCK_FILE_DATE'] = pd.to_datetime(q2['DOCK_FILE_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert year only string to int\n",
    "q2['DE_YR_BUILD'] = pd.to_datetime(q2['DE_YR_BUILD'], format='%Y', errors='coerce')\n",
    "# q2['DE_YR_BUILD'] = q2['DE_YR_BUILD'].fillna(0)\n",
    "# #temp_l = q2['DE_YR_BUILD'].tolist()\n",
    "# #temp_l = [round(num) for num in temp_l]\n",
    "# #q2['DE_YR_BUILD'] = temp_l\n",
    "q2['DE_YR_BUILD'] = pd.DatetimeIndex(q2['DE_YR_BUILD']).year\n",
    "# #q2['DE_YR_BUILD'] = q2['DE_YR_BUILD'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     FLS_DOWNL_DATE  DE_YR_BUILD DOCK_FILE_DATE\n",
       "4662 2020-11-27     NaN          2020-09-21    \n",
       "958  2020-12-22     NaN          2020-10-14    \n",
       "1892 2021-02-08     NaN          2021-01-06    "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>FLS_DOWNL_DATE</th>\n      <th>DE_YR_BUILD</th>\n      <th>DOCK_FILE_DATE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4662</th>\n      <td>2020-11-27</td>\n      <td>NaN</td>\n      <td>2020-09-21</td>\n    </tr>\n    <tr>\n      <th>958</th>\n      <td>2020-12-22</td>\n      <td>NaN</td>\n      <td>2020-10-14</td>\n    </tr>\n    <tr>\n      <th>1892</th>\n      <td>2021-02-08</td>\n      <td>NaN</td>\n      <td>2021-01-06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "q_dates = ['FLS_DOWNL_DATE', 'DE_YR_BUILD', 'DOCK_FILE_DATE']\n",
    "q2[q_dates].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FLS_DOWNL_DATE    datetime64[ns]\n",
       "DE_YR_BUILD       float64       \n",
       "DOCK_FILE_DATE    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "q2[q_dates].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# Export a version for inspection\n",
    "excel_path = \"D:\\\\dev_data\\\\re\\\\pro\\\\fls\\\\excel_reports\\\\\"\n",
    "q2.to_excel(excel_path+'monthly_combined.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2338, 44)"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Fill NAs with zero as drop duplicates does not work with nulls\n",
    "#q2 = q2.astype(str)\n",
    "q2['de_prop_given'] = '0'\n",
    "q2['de_prop_given'][q2['DE_STR_ADD'] != '0']='1'\n",
    "q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id             DE_STR_ADD de_prop_given\n",
       "168   168   9813 ABIGAIL GRACE CT  1           \n",
       "2226  2226  0                      0           \n",
       "47    47    4806 N MAIN            1           "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>DE_STR_ADD</th>\n      <th>de_prop_given</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>168</th>\n      <td>168</td>\n      <td>9813 ABIGAIL GRACE CT</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2226</th>\n      <td>2226</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>47</td>\n      <td>4806 N MAIN</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "q2 = q2.reset_index(drop=True)\n",
    "# Add incremental index\n",
    "q2.insert(0, 'id', range(0, q2.shape[0]))\n",
    "q2[['id', 'DE_STR_ADD', 'de_prop_given']].sample(3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Check to see how many missing values we have for EX_STR_ADD\n",
    "add_l = q2['EX_STR_ADD'].tolist()\n",
    "len([x for x in add_l if x in [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2338, 46)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Tag each dock that has same EX address as 1 else 0\n",
    "ex_add_1 = q2['EX_STR_ADD'].tolist()\n",
    "ex_add_2 = []\n",
    "ex_add_3 = []\n",
    "for l in ex_add_1:\n",
    "    if l not in ex_add_2:\n",
    "        ex_add_2.append(l) \n",
    "        ex_add_3.append(1)\n",
    "    else:\n",
    "        ex_add_3.append(0)\n",
    "q2['unique_ex_add'] = ex_add_3\n",
    "q2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   EX_STR_ADD  unique_ex_add_cume\n",
       "1358  N1098 KNEPPRATH RD       0                 \n",
       "1189  9955 KEMPWOOD DR #935    0                 \n",
       "1867  9949 WOODWIND LN N       0                 \n",
       "1780  9936 COMMON HAWKER CT    0                 \n",
       "2310  9931 KEMP FOREST         0                 \n",
       "1260  9919 DRIFTWOOD PARK DR   0                 \n",
       "2078  9910 ELIZABETHS GLEN LN  0                 \n",
       "949   9910 AVES ST             0                 \n",
       "2127  9901 SHARPCREST ST #K3   0                 \n",
       "334   9825 NE MURDEN COVE      0                 "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EX_STR_ADD</th>\n      <th>unique_ex_add_cume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1358</th>\n      <td>N1098 KNEPPRATH RD</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1189</th>\n      <td>9955 KEMPWOOD DR #935</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1867</th>\n      <td>9949 WOODWIND LN N</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1780</th>\n      <td>9936 COMMON HAWKER CT</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2310</th>\n      <td>9931 KEMP FOREST</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1260</th>\n      <td>9919 DRIFTWOOD PARK DR</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2078</th>\n      <td>9910 ELIZABETHS GLEN LN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>949</th>\n      <td>9910 AVES ST</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2127</th>\n      <td>9901 SHARPCREST ST #K3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>9825 NE MURDEN COVE</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Add cume EX_STR_ADD count \n",
    "q2['unique_ex_add_cume'] = q2.groupby(['EX_STR_ADD'])['unique_ex_add'].cumcount()\n",
    "q2.sort_values(['EX_STR_ADD', 'unique_ex_add_cume'], ascending=[False, False])[['EX_STR_ADD', 'unique_ex_add_cume']][10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Feature engineering\n",
    "### Here we use Tf-idf (term frequencyâ€“inverse document frequency) by looking at a normalized count where each word count is divided by the number of rows (i.e. document) this word appears in. I chose this method instead of for example bag-of-words becasue we are comparing names where on average every document has 3 words in it. And also I am not looking for similarities but actual exact match.\n",
    "\n",
    "I use Tf-idf twice, once to eliminate all documents from lookup dataset that do not have the exact last names like in query data. This will improve the performance. In a second round I will then compare the query data with a smaller loopup data using the second round of Tf-idf."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2336, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "## Prepare TF-IDF for name matching\n",
    "q3 = q2[['id', 'DOCK_NUM','DE_NAME', 'DE_LAST_NAME', 'de_prop_given']]\n",
    "q3 = q3.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "q3['source'] = 'query' # Add this so can identify the array later\n",
    "q3['estate_mask'] = '' # Add placeholder as Lookup data has one\n",
    "q3 = q3.rename(columns={\"DE_NAME\": \"MAILTO_cleaned\", \"DOCK_NUM\": \"ACCOUNT\"})\n",
    "# Remove pro duplicates\n",
    "q3 = q3.drop_duplicates(subset='MAILTO_cleaned', keep=\"last\")\n",
    "q3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id ACCOUNT MAILTO_cleaned DE_LAST_NAME de_prop_given source  \\\n",
       "1295  1295  491243  jessie garza   garza        1             query   \n",
       "2123  2123  487927  karen houston  houston      0             query   \n",
       "\n",
       "     estate_mask  \n",
       "1295              \n",
       "2123              "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>DE_LAST_NAME</th>\n      <th>de_prop_given</th>\n      <th>source</th>\n      <th>estate_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1295</th>\n      <td>1295</td>\n      <td>491243</td>\n      <td>jessie garza</td>\n      <td>garza</td>\n      <td>1</td>\n      <td>query</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2123</th>\n      <td>2123</td>\n      <td>487927</td>\n      <td>karen houston</td>\n      <td>houston</td>\n      <td>0</td>\n      <td>query</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "q3.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify single letter initials in the name so the get picked by in n-gram vectorization\n",
    "def fix_middle_initial(name):\n",
    "    namel = []\n",
    "    namel = list(name.split(' '))\n",
    "    namel_count = []\n",
    "    namel_count = [len(i) for i in namel]\n",
    "    for i, letter_count in enumerate(namel_count):\n",
    "        if letter_count ==1:\n",
    "            namel[i] = namel[i] * 3\n",
    "        else: continue\n",
    "    return ' '.join(namel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last name\n",
    "#q3['l_name'] = q3['MAILTO_cleaned'].str.extract('([\\w\\-]+)$', expand=True)\n",
    "q3['l_name'] = q3['DE_LAST_NAME']\n",
    "q3 = q3.drop('DE_LAST_NAME', axis=1)\n",
    "q3['MAILTO_cleaned2'] = q3['MAILTO_cleaned'].apply(fix_middle_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id ACCOUNT  MAILTO_cleaned de_prop_given source estate_mask  l_name  \\\n",
       "235  235  488365  kathy a howell  1             query              howell   \n",
       "263  263  490646  john c meyer    0             query              meyer    \n",
       "\n",
       "      MAILTO_cleaned2  \n",
       "235  kathy aaa howell  \n",
       "263  john ccc meyer    "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>de_prop_given</th>\n      <th>source</th>\n      <th>estate_mask</th>\n      <th>l_name</th>\n      <th>MAILTO_cleaned2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>235</th>\n      <td>235</td>\n      <td>488365</td>\n      <td>kathy a howell</td>\n      <td>1</td>\n      <td>query</td>\n      <td></td>\n      <td>howell</td>\n      <td>kathy aaa howell</td>\n    </tr>\n    <tr>\n      <th>263</th>\n      <td>263</td>\n      <td>490646</td>\n      <td>john c meyer</td>\n      <td>0</td>\n      <td>query</td>\n      <td></td>\n      <td>meyer</td>\n      <td>john ccc meyer</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "q3.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "# Get difference between two dataset columns before merging them. A match has to return zero element\n",
    "l_columns = list(l4.columns)\n",
    "q_columns = list(q3.columns)\n",
    "set(q_columns) ^ set(l_columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine lookup with query dataset into a new df where can use cosign similarities\n",
    "result = l4.append(q3, sort=False)\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               ACCOUNT          MAILTO_cleaned  source de_prop_given    id  \\\n",
       "874134   1276880010027  carr kirlice v          lookup                       \n",
       "924294   1301260010006  baker kenneth r mary l  lookup                       \n",
       "1020643  487484         cleta r graham          query   0             2298   \n",
       "1019312  488882         vera brown              query   0             966    \n",
       "\n",
       "        estate_mask  l_name             MAILTO_cleaned2  \n",
       "874134   0           carr    carr kirlice vvv            \n",
       "924294   0           baker   baker kenneth rrr mary lll  \n",
       "1020643              graham  cleta rrr graham            \n",
       "1019312              brown   vera brown                  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>id</th>\n      <th>estate_mask</th>\n      <th>l_name</th>\n      <th>MAILTO_cleaned2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>874134</th>\n      <td>1276880010027</td>\n      <td>carr kirlice v</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>carr</td>\n      <td>carr kirlice vvv</td>\n    </tr>\n    <tr>\n      <th>924294</th>\n      <td>1301260010006</td>\n      <td>baker kenneth r mary l</td>\n      <td>lookup</td>\n      <td></td>\n      <td></td>\n      <td>0</td>\n      <td>baker</td>\n      <td>baker kenneth rrr mary lll</td>\n    </tr>\n    <tr>\n      <th>1020643</th>\n      <td>487484</td>\n      <td>cleta r graham</td>\n      <td>query</td>\n      <td>0</td>\n      <td>2298</td>\n      <td></td>\n      <td>graham</td>\n      <td>cleta rrr graham</td>\n    </tr>\n    <tr>\n      <th>1019312</th>\n      <td>488882</td>\n      <td>vera brown</td>\n      <td>query</td>\n      <td>0</td>\n      <td>966</td>\n      <td></td>\n      <td>brown</td>\n      <td>vera brown</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "result.groupby('source').sample(n=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick indexes of two groups for future slicing\n",
    "l_index = result[result['source']=='lookup'].index\n",
    "q_index = result[result['source']=='query'].index"
   ]
  },
  {
   "source": [
    "### Vectorize"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 1-1 word ngrams on last names only\n",
    "vectorizer = TfidfVectorizer(decode_error='replace', strip_accents='unicode', analyzer='word'\n",
    "                                       # ,stop_words='english'\n",
    "                                       ,ngram_range = (1, 1)\n",
    "                                       #, min_df = 1\n",
    "                                       , norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=True)#,\n",
    "                                       \n",
    "                                      #  max_df=1, max_features=None)\n",
    "X = vectorizer.fit_transform(result['l_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['abatan', 'abate', 'abatie', 'abatte', 'abaunza', 'abay', 'abaya', 'abayan', 'abayatissa', 'abayomi', 'abaza', 'abazajian', 'abazie', 'abba', 'abbara', 'abbas', 'abbasi', 'abbasian', 'abbasimalayeri', 'abbasmanesh', 'abbaspour', 'abbassi', 'abbassian', 'abbaszadeh', 'abbaszadehrizi', 'abbate', 'abbe', 'abbey', 'abbie', 'abbinanti', 'abbit', 'abbitt', 'abbot', 'abbott', 'abbouchi', 'abboud', 'abboushi', 'abbrat', 'abbruscato', 'abbs', 'abbud', 'abc', 'abcede', 'abd', 'abdal', 'abdala', 'abdali', 'abdalla', 'abdallah', 'abdani']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[100:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1020683, 120349), 2, 1026165)"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "#nd-array info\n",
    "X.shape, X.ndim, X.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1018347, 2336), 2, 1488330)"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "# Filter away rows where there is no last name from query list \n",
    "# Get similarities of lookup and query dataset \n",
    "sim1 = X[l_index].dot(X[q_index].transpose())\n",
    "sim1.shape, sim1.ndim, sim1.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1488330,)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# Get non zero values' indexes and their values\n",
    "nonzero_tup = np.stack(np.nonzero(sim1), axis=-1)\n",
    "# Filter away zeros and return a list of indexs where there was a match with last names only\n",
    "res_list1 = [x[0] for x in nonzero_tup]\n",
    "# Convert list to array as it is expensive to remvoe duplicates in a large list\n",
    "res_array = np.array(res_list1)\n",
    "res_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(364268,)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "res_uniques = np.unique(res_array) # This is the smaller lookup dataset where there is one exact match of last name for query data\n",
    "res_uniques.shape"
   ]
  },
  {
   "source": [
    "## By using TFIDF and cosine similarities we have reduced the size of lookup dataset from 1 million to 360k. This will improve the performance of futher matching solutions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}