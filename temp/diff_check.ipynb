{
 "cells": [
  {
   "source": [
    "# Use of TF-IDF on large dataset for string matching"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## There are many fuzzy matching algorithms that work fine on small dataset. However, they fall short when used on even modest data sets of greater than a few thousand records. This is because they compare each record to all the other records in the data set. Here we will use TF_IDF to compare list of 2500 names in a lookup database of around 1 million names. The goal is to shrink the lookup dateset to a much smaller size so we can do better n-gram analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "# import matplotlib.pyplot as plt\n",
    "# from matplotlib.pyplot import plot, xlabel, ylabel\n",
    "# %matplotlib inline\n",
    "# from matplotlib.path import Path\n",
    "# from matplotlib.figure import Figure\n",
    "# from matplotlib.patches import PathPatch\n",
    "# from matplotlib.patches import Patch\n",
    "# from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "# import matplotlib.cm as cm\n",

    "from IPython.core.display import display\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import percentile\n",
    "from numpy.random import seed\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "import time\n",
    "import spacy\n",
    "import re\n",
<<<<<<< HEAD
    "import pandas as pd\n",
    "from scipy.stats import bartlett\n",
=======
    "# import pyodbc\n",
    "# # import sqlalchemy as sal\n",
    "# from sklearn.preprocessing import normalize \n",
    "# from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from scipy.stats import bartlett\n",
    "# from scipy.stats import boxcox\n",
    "# from sklearn.preprocessing import normalize \n",
    "# from scipy.stats import jarque_bera\n",
    "# from scipy.stats import levene\n",
    "# from scipy.stats import normaltest\n",
    "# import scipy.stats as stats\n",
    "# from scipy.stats.mstats import winsorize\n",
    "# from scipy.stats import zscore\n",
    "# import seaborn as sns\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",

    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.cluster import DBSCAN\n",
<<<<<<< HEAD
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import xlsxwriter\n",
=======
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.metrics import silhouette_score #\n",
    "# from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "# from sklearn.metrics import precision_recall_curve\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split \n",
    "# from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import xlsxwriter\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "# from sklearn.metrics import homogeneity_score, completeness_score, v_measure_score, \\\n",
    "#     adjusted_mutual_info_score, adjusted_rand_score\n",

    "from sklearn.metrics import silhouette_samples,  silhouette_score\n",
    "from sklearn.metrics.cluster import contingency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_md\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "from random import sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100) \n",
    "pd.set_option('display.max_colwidth', -1) "
   ]
  },
  {
   "source": [
    "## Import two data sources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2536, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "## import the query data\n",
    "import_path = r'D:\\dev_data\\re\\hcad'\n",
    "file_name1 = 'pro_names.csv'\n",
    "file1 = import_path+\"\\\\\"+ file_name1\n",
    "dfp0 = pd.read_csv(file1)\n",
    "dfp0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Unnamed: 0  DOCK_NUM          DE_NAME DE_FIRST_NAME DE_MIDDLE_NAME  \\\n",
       "0  0           471514    CAROLYN A BROWN  CAROLYN       A               \n",
       "1  1           485685    LUCIO SOLIS      LUCIO         NaN             \n",
       "\n",
       "  DE_LAST_NAME  de_target_label  \n",
       "0  BROWN        0                \n",
       "1  SOLIS        1                "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>DOCK_NUM</th>\n      <th>DE_NAME</th>\n      <th>DE_FIRST_NAME</th>\n      <th>DE_MIDDLE_NAME</th>\n      <th>DE_LAST_NAME</th>\n      <th>de_target_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>471514</td>\n      <td>CAROLYN A BROWN</td>\n      <td>CAROLYN</td>\n      <td>A</td>\n      <td>BROWN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>485685</td>\n      <td>LUCIO SOLIS</td>\n      <td>LUCIO</td>\n      <td>NaN</td>\n      <td>SOLIS</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "dfp0.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1087036, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Import lookup data\n",
    "owner_cols = ['ACCOUNT', 'MAILTO']\n",
    "file_name2 = 'ss_owners.csv'\n",
    "file2 = import_path+\"\\\\\"+ file_name2\n",
    "dfo0 = pd.read_csv(file2,  dtype= str, encoding = \"ISO-8859-1\", names=owner_cols, skiprows=1)\n",
    "dfo0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         ACCOUNT                  MAILTO\n",
       "0  0032180000021  SANTOS DOLORES ST JOHN\n",
       "1  0032180000022  GRIMALDO ROSIE        \n",
       "2  0032180000023  GARCIA ANTONIO        "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0032180000021</td>\n      <td>SANTOS DOLORES ST JOHN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0032180000022</td>\n      <td>GRIMALDO ROSIE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0032180000023</td>\n      <td>GARCIA ANTONIO</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dfo0.head(3)"
   ]
  },
  {
   "source": [
    "## Helper functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'\"','',text)\n",
    "    text = re.sub(r'&','',text)\n",
    "    ext = re.sub(\"[\\[].*?[\\]];\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "source": [
    "## Preprocess lookup dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfo1 = dfo0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['santos dolores st john', 'grimaldo rosie', 'garcia antonio']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Convert column of names to string and clean\n",
    "l = dfo1['MAILTO'].tolist() \n",
    "l=['missing' if x is np.nan else x for x in l]\n",
    "s = '||||'.join(l).lower()\n",
    "sc = text_cleaner(s)\n",
    "#sc[:10]\n",
    "names = [str(x) for x in sc.split('||||') if x]\n",
    "names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           MAILTO_cleaned\n",
       "0  santos dolores st john\n",
       "1  grimaldo rosie        \n",
       "2  garcia antonio        "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAILTO_cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>santos dolores st john</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>grimaldo rosie</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>garcia antonio</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "dfo2 = pd.DataFrame(names, index=dfo1.index, columns=['MAILTO_cleaned'])\n",
    "dfo2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1087036, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Combine original df with cleaned names\n",
    "dfo3 = pd.concat([dfo1, dfo2], axis=1)\n",
    "dfo3['source'] = 'owners' # Add this so can identify the array later\n",
    "dfo3['de_prop_given'] = '' # Placeholder for future use\n",
    "dfo3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         ACCOUNT                  MAILTO          MAILTO_cleaned  source  \\\n",
       "0  0032180000021  SANTOS DOLORES ST JOHN  santos dolores st john  owners   \n",
       "1  0032180000022  GRIMALDO ROSIE          grimaldo rosie          owners   \n",
       "2  0032180000023  GARCIA ANTONIO          garcia antonio          owners   \n",
       "\n",
       "  de_prop_given  \n",
       "0                \n",
       "1                \n",
       "2                "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0032180000021</td>\n      <td>SANTOS DOLORES ST JOHN</td>\n      <td>santos dolores st john</td>\n      <td>owners</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0032180000022</td>\n      <td>GRIMALDO ROSIE</td>\n      <td>grimaldo rosie</td>\n      <td>owners</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0032180000023</td>\n      <td>GARCIA ANTONIO</td>\n      <td>garcia antonio</td>\n      <td>owners</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "dfo3.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1087036, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "dfo3 = dfo3.drop_duplicates(subset='ACCOUNT', keep=\"last\")\n",
    "dfo3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tag commercial names by regex pattern\n",
    "def find_pat(text):\n",
    "    if re.search(r\" llc|current owner|  inc| lc| ltd| lp| churchcorp| company|city of houston|\\\n",
    "        county of harris|state of texas| company| harris county|harris county|county of harris|\\\n",
    "            texas department| city of katy|parcel\", text):\n",
    "        return 1\n",
    "    return   0\n",
    "# Applu the function\n",
    "dfo3['non_person'] = dfo3['MAILTO_cleaned'].apply(find_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "68266"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# Number of commercial entries\n",
    "dfo3['non_person'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1018770, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Drop commercial entries\n",
    "dfo3 = dfo3.drop(dfo3[dfo3.non_person ==1].index)\n",
    "dfo3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "              ACCOUNT          MAILTO  MAILTO_cleaned  source de_prop_given  \\\n",
       "90835   0591250080020  HARDY SAMUEL B  hardy samuel b  owners                 \n",
       "813643  1224580020002  LUNA PETRA M    luna petra m    owners                 \n",
       "13406   0170550000017  ROSALES RUBIN   rosales rubin   owners                 \n",
       "\n",
       "        non_person   l_name  \n",
       "90835   0           hardy    \n",
       "813643  0           luna     \n",
       "13406   0           rosales  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>non_person</th>\n      <th>l_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>90835</th>\n      <td>0591250080020</td>\n      <td>HARDY SAMUEL B</td>\n      <td>hardy samuel b</td>\n      <td>owners</td>\n      <td></td>\n      <td>0</td>\n      <td>hardy</td>\n    </tr>\n    <tr>\n      <th>813643</th>\n      <td>1224580020002</td>\n      <td>LUNA PETRA M</td>\n      <td>luna petra m</td>\n      <td>owners</td>\n      <td></td>\n      <td>0</td>\n      <td>luna</td>\n    </tr>\n    <tr>\n      <th>13406</th>\n      <td>0170550000017</td>\n      <td>ROSALES RUBIN</td>\n      <td>rosales rubin</td>\n      <td>owners</td>\n      <td></td>\n      <td>0</td>\n      <td>rosales</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
=======
       "              ACCOUNT                          MAILTO  \\\n",
       "886689  1256990010016  WOODS CHANEATHA NAVON            \n",
       "139000  0690140030035  BUTKEVICH JENNIFER & ALEXANDER   \n",
       "414624  1045440000016  CAMPBELL JONATHAN R              \n",
       "\n",
       "                      MAILTO_cleaned  source de_prop_given  non_person  \\\n",
       "886689  woods chaneatha navon         owners                0            \n",
       "139000  butkevich jennifer alexander  owners                0            \n",
       "414624  campbell jonathan r           owners                0            \n",
       "\n",
       "           l_name  \n",
       "886689  woods      \n",
       "139000  butkevich  \n",
       "414624  campbell   "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>non_person</th>\n      <th>l_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>886689</th>\n      <td>1256990010016</td>\n      <td>WOODS CHANEATHA NAVON</td>\n      <td>woods chaneatha navon</td>\n      <td>owners</td>\n      <td></td>\n      <td>0</td>\n      <td>woods</td>\n    </tr>\n    <tr>\n      <th>139000</th>\n      <td>0690140030035</td>\n      <td>BUTKEVICH JENNIFER &amp; ALEXANDER</td>\n      <td>butkevich jennifer alexander</td>\n      <td>owners</td>\n      <td></td>\n      <td>0</td>\n      <td>butkevich</td>\n    </tr>\n    <tr>\n      <th>414624</th>\n      <td>1045440000016</td>\n      <td>CAMPBELL JONATHAN R</td>\n      <td>campbell jonathan r</td>\n      <td>owners</td>\n      <td></td>\n      <td>0</td>\n      <td>campbell</td>\n    </tr>\n  </tbody>\n</table>\n</div>"

     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# Extract the last name\n",
    "dfo3['l_name'] = dfo3['MAILTO_cleaned'].str.extract('^([\\w\\-]+)', expand=True)\n",
    "dfo3 = dfo3[~dfo3['l_name'].isnull()] # Filter away those names that start with digits\n",
    "dfo3.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1018347, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "dfo3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1018347, 7), (1018347, 7))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "dfo31 = dfo3.copy()\n",
    "#dfo31 = dfo3[:10000]\n",
    "dfo3.shape, dfo31.shape"
   ]
  },
  {
   "source": [
    "## Preprocess querry dataset"
<<<<<<< HEAD
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
=======
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "\"['de_prop_given'] not in index\"",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-fe50e3a67c01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfp0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DOCK_NUM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DE_NAME'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'de_prop_given'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdfp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdfp1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'source'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'prob'\u001b[0m \u001b[1;31m# Add this so can identify the array later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdfp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfp1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"DE_NAME\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"MAILTO_cleaned\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DOCK_NUM\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"ACCOUNT\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Remove pro duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2906\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2907\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2910\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1302\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1304\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;31m# we skip the warning on Categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['de_prop_given'] not in index\""
     ]
    }
   ],

   "source": [
    "dfp1 = dfp0[['DOCK_NUM', 'DE_NAME']]\n",
    "dfp1 = dfp1.applymap(lambda s:s.lower() if type(s) == str else s)\n",
    "dfp1['source'] = 'prob' # Add this so can identify the array later\n",
    "dfp1 = dfp1.rename(columns={\"DE_NAME\": \"MAILTO_cleaned\", \"DOCK_NUM\": \"ACCOUNT\"})\n",
    "# Remove pro duplicates\n",
    "dfp1 = dfp1.drop_duplicates(subset='MAILTO_cleaned', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      ACCOUNT     MAILTO_cleaned source     l_name\n",
       "822   490477   eugene chooran     prob   chooran  \n",
       "2363  489542   michele boles      prob   boles    \n",
       "2007  488242   steven henderson   prob   henderson\n",
       "2433  489680   james l wilkerson  prob   wilkerson\n",
       "1274  489067   donald g wilson    prob   wilson   "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>l_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>822</th>\n      <td>490477</td>\n      <td>eugene chooran</td>\n      <td>prob</td>\n      <td>chooran</td>\n    </tr>\n    <tr>\n      <th>2363</th>\n      <td>489542</td>\n      <td>michele boles</td>\n      <td>prob</td>\n      <td>boles</td>\n    </tr>\n    <tr>\n      <th>2007</th>\n      <td>488242</td>\n      <td>steven henderson</td>\n      <td>prob</td>\n      <td>henderson</td>\n    </tr>\n    <tr>\n      <th>2433</th>\n      <td>489680</td>\n      <td>james l wilkerson</td>\n      <td>prob</td>\n      <td>wilkerson</td>\n    </tr>\n    <tr>\n      <th>1274</th>\n      <td>489067</td>\n      <td>donald g wilson</td>\n      <td>prob</td>\n      <td>wilson</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "# Extract the last name\n",
    "dfp1['l_name'] = dfp1['MAILTO_cleaned'].str.extract('([\\w\\-]+)$', expand=True)\n",
    "dfp1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 23,
=======
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop extra columns\n",
    "dfo31 = dfo31.drop(['MAILTO', 'non_person'], 1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['ACCOUNT', 'MAILTO_cleaned', 'source', 'de_prop_given', 'l_name'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "dfo31.columns"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['ACCOUNT', 'MAILTO_cleaned', 'source', 'l_name'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "dfp1.columns"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine lookup with query dataset\n",
    "result = dfo31.append(dfp1, sort=False)\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               ACCOUNT          MAILTO_cleaned  source de_prop_given   l_name\n",
       "874134   1276880010027  carr kirlice v          owners                carr   \n",
       "924294   1301260010006  baker kenneth r mary l  owners                baker  \n",
       "1018582  490461         elizabeth cowper        prob    NaN           cowper \n",
       "1018519  490572         george g edwards        prob    NaN           edwards"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>l_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>874134</th>\n      <td>1276880010027</td>\n      <td>carr kirlice v</td>\n      <td>owners</td>\n      <td></td>\n      <td>carr</td>\n    </tr>\n    <tr>\n      <th>924294</th>\n      <td>1301260010006</td>\n      <td>baker kenneth r mary l</td>\n      <td>owners</td>\n      <td></td>\n      <td>baker</td>\n    </tr>\n    <tr>\n      <th>1018582</th>\n      <td>490461</td>\n      <td>elizabeth cowper</td>\n      <td>prob</td>\n      <td>NaN</td>\n      <td>cowper</td>\n    </tr>\n    <tr>\n      <th>1018519</th>\n      <td>490572</td>\n      <td>george g edwards</td>\n      <td>prob</td>\n      <td>NaN</td>\n      <td>edwards</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "result.groupby('source').sample(n=2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick indexes of two groups for future slicing\n",
    "l_index = result[result['source']=='owners'].index\n",
    "q_index = result[result['source']=='prob'].index"
   ]
  },
  {
   "source": [
    "# Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Here we use Tf-idf (term frequency–inverse document frequency) by looking at a normalized count where each word count is divided by the number of rows (i.e. document) this word appears in. I chose this method instead of for example bag-of-words becasue we are comparing names where on average every document has 3 words in it. And also I am not looking for similarities but actual exact match."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ACCOUNT, MAILTO_cleaned, source, de_prop_given, l_name]\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>l_name</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "result[result['l_name'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "# use 1-1 word ngrams on last names only\n",
    "vectorizer = TfidfVectorizer(decode_error='replace', strip_accents='unicode', analyzer='word'\n",
    "                                       # ,stop_words='english'\n",
    "                                       ,ngram_range = (1, 1)\n",
    "                                       #, min_df = 1\n",
    "                                       , norm=u'l2', use_idf=True, smooth_idf=True, sublinear_tf=True)#,\n",
    "                                       \n",
    "                                      #  max_df=1, max_features=None)\n",
    "X = vectorizer.fit_transform(result['l_name'])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
=======
   "execution_count": null,

   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names()[:50])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1020102, 120327), 2, 1025585)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "#nd-array info\n",
    "X.shape, X.ndim, X.size"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((1018347, 1755), 2, 1062335)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "# Filter away rows where there is no last name from query list \n",
    "# Get similarities of lookup and query dataset \n",
    "sim1 = X[l_index].dot(X[q_index].transpose())\n",
    "sim1.shape, sim1.ndim, sim1.size"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(315440,)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "# Get non zero values' indexes and their values\n",
    "nonzero_tup = np.stack(np.nonzero(sim1), axis=-1)\n",
    "# Filter away zeros and return a list of indexs where there was a match with last names only\n",
    "res_list1 = [x[0] for x in nonzero_tup]\n",
    "# Convert list to array as it is expensitve to remvoe duplicates in a large list\n",
    "res_array = np.array(res_list1)\n",
    "res_uniques = np.unique(res_array) # This is the smaller lookup dataset where there is one exact match of last name for query data\n",
    "res_uniques.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(315440, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "# Drop irrelevant rows from the original 'combined' dataset\n",
    "result1 = result.iloc[res_uniques]\n",
    "# Keep only \"owner\" rows\n",
    "result1 = result1[result['source']=='owners']\n",
    "result1.shape"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              ACCOUNT     MAILTO_cleaned  source de_prop_given    l_name\n",
       "125493  0651220080105  ramirez maritza p  owners                ramirez \n",
       "847090  1262310030043  martinez victor    owners                martinez"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ACCOUNT</th>\n      <th>MAILTO_cleaned</th>\n      <th>source</th>\n      <th>de_prop_given</th>\n      <th>l_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>125493</th>\n      <td>0651220080105</td>\n      <td>ramirez maritza p</td>\n      <td>owners</td>\n      <td></td>\n      <td>ramirez</td>\n    </tr>\n    <tr>\n      <th>847090</th>\n      <td>1262310030043</td>\n      <td>martinez victor</td>\n      <td>owners</td>\n      <td></td>\n      <td>martinez</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],

   "source": [
    "result1.groupby('source').sample(n=2, random_state=1)"
   ]
  },
  {
   "source": [
    "### We have now reduced the 1 million lookup database to over 300,000 names. This will make it easier to perfomr a faster and better n-gram vectorization for the final match."
   ],
   "cell_type": "markdown",
   "metadata": {}
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
=======
        
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}