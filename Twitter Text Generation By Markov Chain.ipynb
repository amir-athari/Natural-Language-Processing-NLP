{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3-final"
    },
    "colab": {
      "name": "Cornell Movie Dialogs Chatbot.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKDsN6Wz7l25"
      },
      "source": [
        "# Twitter US Airline Sentiment Text Generation By Markov Chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8rTDCHw7l2_"
      },
      "source": [
        "### Here we will generate random and simple sentences based on two criteria:\n",
        "1. They should be grammatically correct.\n",
        "2. They should make sense—or at least some sense!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-t-teZP7l3A"
      },
      "source": [
        "### Data: https://www.kaggle.com/crowdflower/twitter-airline-sentiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pzQpB3Qwapx",
        "outputId": "22d8f436-7ba7-4f53-e715-0e00546e7d50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install markovify"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting markovify\n",
            "  Downloading https://files.pythonhosted.org/packages/33/92/4036691c7ea53e545e98e0ffffcef357ca19aa2405df366ae5b8b7da391a/markovify-0.8.3.tar.gz\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 8.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: markovify\n",
            "  Building wheel for markovify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for markovify: filename=markovify-0.8.3-cp36-none-any.whl size=18415 sha256=6b73710f74e45bb7720303c1b1ed971b88e23a0dd60da291f784b8dd97d592ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/e5/be/8e61715070048813947af5fb32f47b4cf9dddd37c965800bdb\n",
            "Successfully built markovify\n",
            "Installing collected packages: unidecode, markovify\n",
            "Successfully installed markovify-0.8.3 unidecode-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIZlTV3l7l3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2399378d-660d-44ae-b8ce-7976fc839898"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import gutenberg\n",
        "import re\n",
        "import spacy\n",
        "import warnings\n",
        "import markovify\n",
        "from sqlalchemy import create_engine\n",
        "#from chatterbot import ChatBot\n",
        "#from chatterbot.trainers import ListTrainer, ChatterBotCorpusTrainer\n",
        "#from chatterbot.conversation import Statement\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('gutenberg')\n",
        "!python -m spacy download en"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbthOX2x7l3B"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ4j3COk7l3C"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'twitter_sentiment'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "df0 = pd.read_sql_query('select * from twitter', con=engine)\n",
        "\n",
        "# no need for an open connection, \n",
        "# as we're only doing a single query\n",
        "engine.dispose()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5NCTznm7l3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3726789b-a192-4d86-de43-2980fe8e947a"
      },
      "source": [
        "nRow, nCol = df0.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 14640 rows and 16 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrUvv6zh7l3C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "b81426e3-fc9c-4a7d-b9a4-25b45c7a7dad"
      },
      "source": [
        "df0.head(2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index            tweet_id  ... tweet_location               user_timezone\n",
              "0      0  570306133677760513  ...           None  Eastern Time (US & Canada)\n",
              "1      1  570301130888122368  ...           None  Pacific Time (US & Canada)\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24_QsTSI7l3D"
      },
      "source": [
        "# Let's focus on negative and positive sentiments seperately\n",
        "df1 = df0.sample(14000)\n",
        "df1_neg = df1[df1['airline_sentiment'] == 'negative']\n",
        "df1_pos = df1[df1['airline_sentiment'] == 'positive']\n",
        "#df1_pos = df0.copy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqqYprrG7l3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7bdb7f-cbe4-4599-f2c0-19d3f41ce53b"
      },
      "source": [
        "df1_neg.shape, df1_pos.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8772, 16), (2245, 16))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Oo5G7O7l3E"
      },
      "source": [
        "# Utility function for standard text cleaning\n",
        "def text_cleaner(text):\n",
        "    text = re.sub(r'--','',text)\n",
        "    text = re.sub(\"[\\[]*[\\]]\", \"\", text)\n",
        "    text = re.sub(\"\\@\", \"\", text)\n",
        "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
        "    text = re.sub(r\"(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)\", \"\", text) # remove links\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N237TuCJ7l3E"
      },
      "source": [
        "df1_pos['cleaned'] = df1_pos['text'].astype(str).apply(text_cleaner)\n",
        "df1_neg['cleaned'] = df1_neg['text'].astype(str).apply(text_cleaner)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUVITZcN7l3F"
      },
      "source": [
        "# Convert the text in column to a body of text\n",
        "dialogs_neg = df1_neg['cleaned'].tolist()\n",
        "dialogs_neg_doc = ''.join(dialogs_neg)\n",
        "\n",
        "# Convert the text in column to a body of text\n",
        "dialogs_pos = df1_pos['cleaned'].tolist()\n",
        "dialogs_pos_doc = ''.join(dialogs_pos)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LBHEi5kwJqp",
        "outputId": "cac2ef81-9730-46c6-84f2-cd8e6aefd8bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(dialogs_neg_doc), len(dialogs_pos_doc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(945709, 180170)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_1vY52PwJqp",
        "outputId": "a8f45a7b-33d1-4799-a189-93199f58a679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "type(dialogs_neg_doc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYhaDAkQwJqq"
      },
      "source": [
        "# Function to remove emojis\n",
        "def deEmojify(text):\n",
        "    regrex_pattern = re.compile(pattern = \"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags = re.UNICODE)\n",
        "    return regrex_pattern.sub(r'',text)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBon82z0wJqq"
      },
      "source": [
        "# Remove emojis\n",
        "dialogs_neg_doc = deEmojify(dialogs_neg_doc)\n",
        "dialogs_pos_doc = deEmojify(dialogs_pos_doc)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JQ6GVbY7l3F"
      },
      "source": [
        "# Adust NLP for a large body of text\n",
        "nlp.max_length = 6000000 # or even higher\n",
        "dialogs_neg_doc = nlp(dialogs_neg_doc)\n",
        "dialogs_pos_doc = nlp(dialogs_pos_doc)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFIcOQ847l3F"
      },
      "source": [
        "## Break the body to sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoPtJ4Xo7l3G"
      },
      "source": [
        "dialogs_neg_sents = [sent.text for sent in dialogs_neg_doc.sents if len(sent.text) > 1]\n",
        "dialogs_pos_sents = [sent.text for sent in dialogs_pos_doc.sents if len(sent.text) > 1]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bTErYn8wJqr"
      },
      "source": [
        "### To generate the transition probabilities, we wil use Markovify's `Text()` class. This class has a parameter called `state_size`. This parameter determines how many words the model uses as the current state. For example, if we want to generate the next word by looking at just the previous word, set `state_size=1`. If we want to generate the next word by looking at the previous two words, then set `state_size=2`. The following is set to `state_size=3`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91Knj8GLwJqr"
      },
      "source": [
        "dialogs_neg_generator = markovify.Text(dialogs_neg_sents, state_size = 3)\n",
        "dialogs_pos_generator = markovify.Text(dialogs_pos_sents, state_size = 3)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJvWp8LGwJqr"
      },
      "source": [
        "### At this stage, we've trained a Markov chain model from *twitter*. Now, we're all set to generate random sentences from this model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rzy73pRkwJqs",
        "outputId": "2911c850-b48f-4495-a044-f6076b4b536e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Three randomly generated negative sentences\n",
        "for i in range(3):\n",
        "    print(dialogs_neg_generator.make_sentence())\n",
        "\n",
        "# Three randomly generated sentences of no more than 100 characters\n",
        "for i in range(3):\n",
        "    print(dialogs_neg_generator.make_short_sentence(100))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "how is it that my flight # can arrive early and be delayed due to poor communication, which sounded like it was salvaged from the 80s.\n",
            "hopefully to the Late Flightr flight from PHL.SouthwestAir\n",
            "PLEASE HELP!SouthwestAir if this flight is to your team.\n",
            "you asked me to follow them to try and resolveAmericanAir my flight to BWI to wait for from buffalo?\n",
            "now been on hold for an hour due to computers being down.\n",
            "hey I got a bad exchange rate.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RSSaJ0KwJqs",
        "outputId": "61faa582-7f7d-4ccb-987c-667af097417f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Three randomly generated positive sentences\n",
        "for i in range(3):\n",
        "    print(dialogs_pos_generator.make_sentence())\n",
        "\n",
        "# Three randomly generated sentences of no more than 100 characters\n",
        "for i in range(3):\n",
        "    print(dialogs_pos_generator.make_short_sentence(100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This has to be the best video I have seen in years of flying USAir.\n",
            "None\n",
            "I needed to change my flight that was Cancelled Flighted and rescheduled for today.\n",
            "I would be so awesome to see!JetBlue\n",
            "AmericanAirUnited is the best first class I have ever flown any other airlines!\n",
            "SouthwestAir thanks for the show!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2X8OJBywJqs"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWbepVUuwJqs"
      },
      "source": [
        "## The sentences do sound good but not very natural and to improve the performance of the model, we can use some syntactic information like part-of-speech tags. The Markovify package also supports this and can work together with spaCy as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7f5k_YewJqt"
      },
      "source": [
        "class POSifiedText(markovify.Text):\n",
        "    \n",
        "    def word_split(self, sentence):\n",
        "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
        "\n",
        "    def word_join(self, words):\n",
        "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
        "        return sentence"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFRlHG6wwJqt"
      },
      "source": [
        "### Now, train a Markov chain model again. This time, use the `POSifiedText()` class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJyk2LRzwJqt"
      },
      "source": [
        "dialogs_neg_generator = POSifiedText(dialogs_neg_sents, state_size = 3)\n",
        "dialogs_pos_generator = POSifiedText(dialogs_pos_sents, state_size = 3)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBsCTUOpwJqt",
        "outputId": "f15f012a-ccc9-4f1d-8518-b1827ecb37fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Three randomly generated negative sentences\n",
        "for i in range(3):\n",
        "    print(dialogs_neg_generator.make_sentence())\n",
        "\n",
        "# Three randomly generated sentences of no more than 100 characters\n",
        "for i in range(3):\n",
        "    print(dialogs_neg_generator.make_short_sentence(100))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2nd plane forced to get off the plane - so frustratedunited\n",
            "can we get a refund?SouthwestAir\n",
            "What 's your excuse this time for delay from LGA to BOS for any shuttle flight ?\n",
            "If that 's true I never want to deal with me in person .\n",
            "I take JetBlue because I 've had with Jet Blue .\n",
            "WELL't be on this plane at  its  now and still have had to .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCH89rrZwJqt",
        "outputId": "f99c8ce1-9b86-4c66-aa04-f09803d032d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Three randomly generated positive sentences\n",
        "for i in range(3):\n",
        "    print(dialogs_pos_generator.make_sentence())\n",
        "\n",
        "# Three randomly generated sentences of no more than 100 characters\n",
        "for i in range(3):\n",
        "    print(dialogs_pos_generator.make_short_sentence(100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "None\n",
            "non stop CMH - OAK has me daydreaming about a trip to Cali & lt;united Hi , flight .\n",
            "exceptional customer service today !\n",
            "Thanks so much , that helps a lot .\n",
            "you should know the crew today on flight # from IND to PHX!!JetBlue\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US67BkeuwJqu"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHe_9H9awJqv"
      },
      "source": [
        "## These generators work very well. Both negative and positve texts show meaninful semantic and syntax."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvXMOatWwJqv"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}