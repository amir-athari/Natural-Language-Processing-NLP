{
 "cells": [
  {
   "source": [
    "# Texas Classification Using TF-IDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Here we will use a simple text dataset consisting of senteces about Monty Python and describing ice cream flavors.\n",
    "### The unit of observation (*documents*) will be the sentences of these topics."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import re\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "import warnings\n",
    "from sklearn import (datasets, model_selection, feature_extraction, linear_model, naive_bayes, ensemble)\n",
    "import collections\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import re\n",
    "import multiprocessing as mp \n",
    "import textacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#!python -m spacy download en\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('gutenberg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "path = \"D:\\\\Dropbox\\\\dev_data\\\\re\\\\pro\\\\tf_idf_data.csv\"\n",
    "df0 = pd.DataFrame()\n",
    "df0 = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text         label\n",
       "0  \"The best Monty Python sketch is the one about...  Monty Python\n",
       "1   \"I laugh when I think about Python's Ministry...  Monty Python\n",
       "2   \"Chocolate is the best ice cream dessert topp...     Ice Cream\n",
       "3   \"The Lumberjack Song is the funniest Monty Py...  Monty Python\n",
       "4   \"I would rather put strawberries on my ice cr...     Ice Cream"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"The best Monty Python sketch is the one about...</td>\n      <td>Monty Python</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I laugh when I think about Python's Ministry...</td>\n      <td>Monty Python</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Chocolate is the best ice cream dessert topp...</td>\n      <td>Ice Cream</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"The Lumberjack Song is the funniest Monty Py...</td>\n      <td>Monty Python</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"I would rather put strawberries on my ice cr...</td>\n      <td>Ice Cream</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "source": [
    "### A helper function for removing some punctuation marks and numbers from the text:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################# DO NOT DELETE ############################################# \n",
    "# Function to move specific column to the left side for easier view\n",
    "def move_to_left(df, column_name):\n",
    "    df= df[ [str(column_name)] + [ col for col in df.columns if col != str(column_name) ] ]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'\"','',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]];\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['cleaned'] = df0['text'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df0.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text         label  \\\n",
       "0  \"The best Monty Python sketch is the one about...  Monty Python   \n",
       "1   \"I laugh when I think about Python's Ministry...  Monty Python   \n",
       "\n",
       "                                             cleaned  \n",
       "0    good monty python sketch dead parrot laugh hard  \n",
       "1  laugh think python ministry silly walk sketch ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"The best Monty Python sketch is the one about...</td>\n      <td>Monty Python</td>\n      <td>good monty python sketch dead parrot laugh hard</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I laugh when I think about Python's Ministry...</td>\n      <td>Monty Python</td>\n      <td>laugh think python ministry silly walk sketch ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1['cleaned'] = [','.join(ele.split()) for ele in df1['cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['cleaned'] = df1['cleaned'].str.replace(\"[^\\w\\s]\", \"\").str.lower()\n",
    "\n",
    "df1['cleaned'] = df1['cleaned'].apply(lambda text: \n",
    "                                          \" \".join(token.lemma_ for token in nlp(text) \n",
    "                                                   if not token.is_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text         label  \\\n",
       "0  \"The best Monty Python sketch is the one about...  Monty Python   \n",
       "1   \"I laugh when I think about Python's Ministry...  Monty Python   \n",
       "\n",
       "                                             cleaned  \n",
       "0    good monty python sketch dead parrot laugh hard  \n",
       "1  laugh think python ministry silly walk sketch ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>cleaned</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"The best Monty Python sketch is the one about...</td>\n      <td>Monty Python</td>\n      <td>good monty python sketch dead parrot laugh hard</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"I laugh when I think about Python's Ministry...</td>\n      <td>Monty Python</td>\n      <td>laugh think python ministry silly walk sketch ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "df1.head(2)"
   ]
  },
  {
   "source": [
    "# Prepare Vertorization using 1-gram and 2-grams"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-gram\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5, min_df=1, use_idf=True, norm=u'l2', smooth_idf=True, ngram_range=(1,1))\n",
    "\n",
    "# applying the vectorizer\n",
    "X = vectorizer.fit_transform(df1[\"cleaned\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "df_1gram = pd.concat([tfidf_df, df1[[ \"label\"]]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-grams\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5, min_df=1, use_idf=True, norm=u'l2', smooth_idf=True, ngram_range=(1,2))\n",
    "\n",
    "# applying the vectorizer\n",
    "X = vectorizer.fit_transform(df1[\"cleaned\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "df_2gram = pd.concat([tfidf_df, df1[[\"label\"]]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   accompaniment       bit  caramel  chocolate     cream      dead   dessert  \\\n",
       "0            0.0  0.000000      0.0    0.00000  0.000000  0.434231  0.000000   \n",
       "1            0.0  0.000000      0.0    0.00000  0.000000  0.000000  0.000000   \n",
       "2            0.0  0.000000      0.0    0.44236  0.306252  0.000000  0.362742   \n",
       "3            0.0  0.370029      0.0    0.00000  0.000000  0.000000  0.000000   \n",
       "4            0.0  0.000000      0.0    0.00000  0.392555  0.000000  0.464964   \n",
       "\n",
       "   fantastic  funniest     funny  ...     silly    sketch      song  \\\n",
       "0        0.0  0.000000  0.000000  ...  0.000000  0.356076  0.000000   \n",
       "1        0.0  0.000000  0.793233  ...  0.264411  0.216821  0.000000   \n",
       "2        0.0  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3        0.0  0.370029  0.000000  ...  0.000000  0.000000  0.370029   \n",
       "4        0.0  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "\n",
       "   strawberry     taste  tasty     think      top      walk         label  \n",
       "0    0.000000  0.000000    0.0  0.000000  0.00000  0.000000  Monty Python  \n",
       "1    0.000000  0.000000    0.0  0.216821  0.00000  0.264411  Monty Python  \n",
       "2    0.000000  0.306252    0.0  0.000000  0.44236  0.000000     Ice Cream  \n",
       "3    0.000000  0.000000    0.0  0.303429  0.00000  0.000000  Monty Python  \n",
       "4    0.567019  0.392555    0.0  0.000000  0.00000  0.000000     Ice Cream  \n",
       "\n",
       "[5 rows x 31 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>accompaniment</th>\n      <th>bit</th>\n      <th>caramel</th>\n      <th>chocolate</th>\n      <th>cream</th>\n      <th>dead</th>\n      <th>dessert</th>\n      <th>fantastic</th>\n      <th>funniest</th>\n      <th>funny</th>\n      <th>...</th>\n      <th>silly</th>\n      <th>sketch</th>\n      <th>song</th>\n      <th>strawberry</th>\n      <th>taste</th>\n      <th>tasty</th>\n      <th>think</th>\n      <th>top</th>\n      <th>walk</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.434231</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.356076</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>Monty Python</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.793233</td>\n      <td>...</td>\n      <td>0.264411</td>\n      <td>0.216821</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.216821</td>\n      <td>0.00000</td>\n      <td>0.264411</td>\n      <td>Monty Python</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.44236</td>\n      <td>0.306252</td>\n      <td>0.000000</td>\n      <td>0.362742</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.306252</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.44236</td>\n      <td>0.000000</td>\n      <td>Ice Cream</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.370029</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.370029</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.370029</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.303429</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>Monty Python</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.392555</td>\n      <td>0.000000</td>\n      <td>0.464964</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.567019</td>\n      <td>0.392555</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>Ice Cream</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "df_1gram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((6, 31), (6, 70))"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "df_1gram.shape, df_2gram.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Use multiple machine learning algorithms on 1-gram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_1gram['label']\n",
    "X = np.array(df_1gram.drop(['label'], 1))\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "lr_params = {\"penalty\": [\"l2\"]}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfc_params = {\"n_estimators\": [3, 5, 10, 15], \"max_depth\": [2, 3, 4, 5], \"min_samples_split\": [3, 5, 7, 9]}\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gbc_params = {\"n_estimators\": [3, 5, 10, 15],\"max_depth\": [2, 3, 4, 5], \"min_samples_split\": [3, 5, 7, 9]}\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "SDG_params= {'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e3], 'penalty': ['l2'], 'n_jobs': [-1]}\n",
    "SDG = linear_model.SGDClassifier()\n",
    "\n",
    "NB_Multi_params = {'alpha': [1.0]}\n",
    "NB_Multi= naive_bayes.MultinomialNB()\n",
    "\n",
    "NB_Bern_params = {'alpha': [1.0]}\n",
    "NB_Bern = naive_bayes.BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=BernoulliNB(), param_grid={'alpha': [1.0]})"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "# GridsearchCV\n",
    "clf_lr = GridSearchCV(lr, lr_params, cv=2)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "clf_rfc = GridSearchCV(rfc, rfc_params, cv=2)\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "\n",
    "clf_gbc = GridSearchCV(gbc, gbc_params, cv=2)\n",
    "clf_gbc.fit(X_train, y_train)\n",
    "\n",
    "clf_SDG = GridSearchCV(SDG, SDG_params, cv=2)\n",
    "clf_SDG.fit(X_train, y_train)\n",
    "\n",
    "clf_NB_Multi = GridSearchCV(NB_Multi, NB_Multi_params, cv=2)\n",
    "clf_NB_Multi.fit(X_train, y_train)\n",
    "\n",
    "clf_NB_Bern = GridSearchCV(NB_Bern, NB_Bern_params, cv=2)\n",
    "clf_NB_Bern.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "# Fit the models\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "SDG.fit(X_train, y_train)\n",
    "NB_Multi.fit(X_train, y_train)\n",
    "NB_Bern.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------Logistic Regression Scores----------------------\nTraining set score: 0.6666666666666666\n\nTest set score: 0.3333333333333333\n----------------------Random Forest Scores----------------------\nTraining set score: 1.0\n\nTest set score: 1.0\n----------------------Gradient Boosting Scores----------------------\nTraining set score: 1.0\n\nTest set score: 1.0\n----------------------Stochastic Gradient Descent Scores----------------------\nTraining set score: 1.0\n\nTest set score: 1.0\n---------------------- Naive Bayes Multinominal Scores----------------------\nTraining set score: 1.0\n\nTest set score: 0.3333333333333333\n----------------------Naive Bayes Bernoulli Scores----------------------\nTraining set score: 1.0\n\nTest set score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check some basic performance\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', gbc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Stochastic Gradient Descent Scores----------------------\")\n",
    "print('Training set score:', SDG.score(X_train, y_train))\n",
    "print('\\nTest set score:', SDG.score(X_test, y_test))\n",
    "\n",
    "print(\"---------------------- Naive Bayes Multinominal Scores----------------------\")\n",
    "print('Training set score:', NB_Multi.score(X_train, y_train))\n",
    "print('\\nTest set score:', NB_Multi.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Naive Bayes Bernoulli Scores----------------------\")\n",
    "print('Training set score:', NB_Bern.score(X_train, y_train))\n",
    "print('\\nTest set score:', NB_Bern.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Use multiple machine learning algorithms on 2-grama:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_2gram['label']\n",
    "X = np.array(df_2gram.drop(['label'], 1))\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "lr_params = {\"penalty\": [\"l2\"]}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfc_params = {\"n_estimators\": [3, 5, 10, 15], \"max_depth\": [2, 3, 4, 5], \"min_samples_split\": [3, 5, 7, 9]}\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gbc_params = {\"n_estimators\": [3, 5, 10, 15],\"max_depth\": [2, 3, 4, 5], \"min_samples_split\": [3, 5, 7, 9]}\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "SDG_params= {'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e3], 'penalty': ['l2'], 'n_jobs': [-1]}\n",
    "SDG = linear_model.SGDClassifier()\n",
    "\n",
    "NB_Multi_params = {'alpha': [1.0]}\n",
    "NB_Multi= naive_bayes.MultinomialNB()\n",
    "\n",
    "NB_Bern_params = {'alpha': [1.0]}\n",
    "NB_Bern = naive_bayes.BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=BernoulliNB(), param_grid={'alpha': [1.0]})"
      ]
     },
     "metadata": {},
     "execution_count": 111
    }
   ],
   "source": [
    "# GridsearchCV\n",
    "clf_lr = GridSearchCV(lr, lr_params, cv=2)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "clf_rfc = GridSearchCV(rfc, rfc_params, cv=2)\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "\n",
    "clf_gbc = GridSearchCV(gbc, gbc_params, cv=2)\n",
    "clf_gbc.fit(X_train, y_train)\n",
    "\n",
    "clf_SDG = GridSearchCV(SDG, SDG_params, cv=2)\n",
    "clf_SDG.fit(X_train, y_train)\n",
    "\n",
    "clf_NB_Multi = GridSearchCV(NB_Multi, NB_Multi_params, cv=2)\n",
    "clf_NB_Multi.fit(X_train, y_train)\n",
    "\n",
    "clf_NB_Bern = GridSearchCV(NB_Bern, NB_Bern_params, cv=2)\n",
    "clf_NB_Bern.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "# Fit the models\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "SDG.fit(X_train, y_train)\n",
    "NB_Multi.fit(X_train, y_train)\n",
    "NB_Bern.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------------Logistic Regression Scores----------------------\nTraining set score: 0.6666666666666666\n\nTest set score: 0.3333333333333333\n----------------------Random Forest Scores----------------------\nTraining set score: 1.0\n\nTest set score: 0.6666666666666666\n----------------------Gradient Boosting Scores----------------------\nTraining set score: 1.0\n\nTest set score: 0.3333333333333333\n----------------------Stochastic Gradient Descent Scores----------------------\nTraining set score: 1.0\n\nTest set score: 1.0\n---------------------- Naive Bayes Multinominal Scores----------------------\nTraining set score: 1.0\n\nTest set score: 0.3333333333333333\n----------------------Naive Bayes Bernoulli Scores----------------------\nTraining set score: 1.0\n\nTest set score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Check some basic performance\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', gbc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Stochastic Gradient Descent Scores----------------------\")\n",
    "print('Training set score:', SDG.score(X_train, y_train))\n",
    "print('\\nTest set score:', SDG.score(X_test, y_test))\n",
    "\n",
    "print(\"---------------------- Naive Bayes Multinominal Scores----------------------\")\n",
    "print('Training set score:', NB_Multi.score(X_train, y_train))\n",
    "print('\\nTest set score:', NB_Multi.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Naive Bayes Bernoulli Scores----------------------\")\n",
    "print('Training set score:', NB_Bern.score(X_train, y_train))\n",
    "print('\\nTest set score:', NB_Bern.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Conclustion\n",
    "\n",
    "Adding 2-grams did not improve the result. However, because the dateset is very small we are facing overfitting problems."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "49px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}