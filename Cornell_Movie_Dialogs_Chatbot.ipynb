{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "Cornell Movie Dialogs Chatbot.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKDsN6Wz7l25"
      },
      "source": [
        "# Cornell Movie Dialogs ChatBot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8rTDCHw7l2_"
      },
      "source": [
        "## We will develop a simple chatbot by training it on Cornell Movie Dialogs corpus containing a large metadata-rich collection of fictional conversations extracted from raw movie scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-t-teZP7l3A"
      },
      "source": [
        "### Data: http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5KdHv1x7wmR",
        "outputId": "a51d4373-0b16-4db8-a7c9-fa227e9d4698",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install chatterbot"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting chatterbot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/21/85c2b114bd9dfabdd46ba58fc4519acdaed45d8c70898d40079e37a45e67/ChatterBot-1.0.8-py2.py3-none-any.whl (63kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 20kB 25.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 30kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 40kB 9.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 51kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2018.9)\n",
            "Requirement already satisfied: sqlalchemy<1.4,>=1.3 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (1.3.20)\n",
            "Collecting mathparse<0.2,>=0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/e5/4910fb85950cb960fcf3f5aabe1c8e55f5c9201788a1c1302b570a7e1f84/mathparse-0.1.2-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil<2.9,>=2.8 in /usr/local/lib/python3.6/dist-packages (from chatterbot) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.9,>=2.8->chatterbot) (1.15.0)\n",
            "Installing collected packages: mathparse, chatterbot\n",
            "Successfully installed chatterbot-1.0.8 mathparse-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIZlTV3l7l3A",
        "outputId": "694612f9-6a50-46dd-e757-77cfe6ba202c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import gutenberg\n",
        "import re\n",
        "import spacy\n",
        "import warnings\n",
        "from sqlalchemy import create_engine\n",
        "from chatterbot import ChatBot\n",
        "from chatterbot.trainers import ListTrainer, ChatterBotCorpusTrainer\n",
        "from chatterbot.conversation import Statement\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "nltk.download('gutenberg')\n",
        "!python -m spacy download en"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbthOX2x7l3B"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ4j3COk7l3C"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'cornell_movie_dialogs'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "df0 = pd.read_sql_query('select * from dialogs', con=engine)\n",
        "\n",
        "# no need for an open connection, \n",
        "# as we're only doing a single query\n",
        "engine.dispose()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5NCTznm7l3C",
        "outputId": "d2812653-2f99-490a-fa94-77daf157afd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nRow, nCol = df0.shape\n",
        "print(f'There are {nRow} rows and {nCol} columns')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 304446 rows and 2 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrUvv6zh7l3C",
        "outputId": "2679a5ec-90d8-4b3f-fc18-b8f765441114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "df0.head(4)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>dialogs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Okay... then how 'bout we try out some French ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                            dialogs\n",
              "0      0  Can we make this quick?  Roxanne Korrine and A...\n",
              "1      1  Well, I thought we'd start with pronunciation,...\n",
              "2      2  Not the hacking and gagging and spitting part....\n",
              "3      3  Okay... then how 'bout we try out some French ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24_QsTSI7l3D"
      },
      "source": [
        "df1 = df0.sample(100000)\n",
        "#df1 = df0.copy()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqqYprrG7l3D",
        "outputId": "c5807e0a-323b-460d-faf3-5f1c4040351d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Oo5G7O7l3E"
      },
      "source": [
        "# Utility function for standard text cleaning\n",
        "def text_cleaner(text):\n",
        "    text = re.sub(r'--','',text)\n",
        "    text = re.sub(\"[\\[]*[\\]]\", \"\", text)\n",
        "    text = re.sub(\"[\\[]*[\\]]\", \"\", text)\n",
        "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N237TuCJ7l3E"
      },
      "source": [
        "# df1['cleaned'] = df1['dialogs'].astype(str).apply(text_cleaner)\n",
        "# df1['tokens'] = df1['cleaned'].apply(lambda x: nlp(x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUVITZcN7l3F",
        "outputId": "78d1fa7c-a3e1-4b0e-db70-fc041050ba65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Convert the text in column to a body of text\n",
        "dialogs = df1['dialogs'].tolist()\n",
        "dialogs_doc = ''.join(dialogs)\n",
        "len(dialogs_doc)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5552745"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JQ6GVbY7l3F"
      },
      "source": [
        "nlp.max_length = 6000000 # or even higher"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqSmlYSR7l3F"
      },
      "source": [
        "dialogs_doc = nlp(dialogs_doc)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFIcOQ847l3F"
      },
      "source": [
        "## Break the body to sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoPtJ4Xo7l3G",
        "outputId": "3acbba8f-3a7a-43bc-ea18-ca7c7de3bc51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dialogs_sents = [sent.text for sent in dialogs_doc.sents if len(sent.text) > 1]\n",
        "dialogs_sents[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I'm trying!One country did sponsor the resolution.\",\n",
              " 'A land called \"El Salvador\".',\n",
              " 'To tear down the Walls of Jericho.',\n",
              " 'Sounds good',\n",
              " ', where are you now?You like',\n",
              " 'sports?Oh',\n",
              " 'yeah.',\n",
              " \"They'll never catch the guy.\",\n",
              " 'The yellow one.',\n",
              " \"Gee--I'm sorry about that, Miss--you\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlkjKnZ67l3G"
      },
      "source": [
        "## Now we can create our own chatbot and train it using this corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vHjqzhy7l3G",
        "outputId": "9263466e-eb3d-41bc-9c65-dd04824c63df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Create a chatbot\n",
        "chatbot = ChatBot('MovieExpert')\n",
        "# This is to remove the accumulated knowledge base\n",
        "chatbot.storage.drop()\n",
        "\n",
        "# Create a new trainer for the chatbot\n",
        "trainer = ListTrainer(chatbot)\n",
        "\n",
        "# Train the chatbot based on Persuasion\n",
        "trainer.train(dialogs_sents)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List Trainer: [####################] 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQxHfEpx7l3G"
      },
      "source": [
        "### Here we create a function to engage the user if the text contains any greeting words. And if it contains one of them, the chatbot will respond with another greeting word."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxIMivzT7l3H"
      },
      "source": [
        "GREETING_INPUTS = [\"hello\", \"hi\", \"greetings\", \"what's up\",\"hey\"]\n",
        "GREETING_RESPONSES = [\"hello\", \"hi\", \"hey\", \"hi there\"]\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc4nGWoc7l3H"
      },
      "source": [
        "## Now we run the chatpot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne9Cj3c77l3H",
        "outputId": "744311f8-8fd5-4909-fbd8-8b23a738d6e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"MovieExpert: I will try to respond to you reasonably. If you want to exit, type bye.\")\n",
        "\n",
        "# Below is the chatting\n",
        "while True:\n",
        "    \n",
        "    user_input = input(\"User: \")\n",
        "    user_input=user_input.lower()\n",
        "    \n",
        "    if(user_input!='bye'):\n",
        "        if(user_input == 'thanks' or user_input == 'thank you'):\n",
        "            break\n",
        "            print(\"MovieExpert: You're welcome.\")\n",
        "        else:\n",
        "            if(greeting(user_input) != None):\n",
        "                print(\"MovieExpert: \" + greeting(user_input))\n",
        "            else:\n",
        "                print(\"MovieExpert: \", end = \"\")\n",
        "                print(chatbot.get_response(user_input))\n",
        "    else:\n",
        "        print(\"MovieExpert: Bye! It was a great chat.\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MovieExpert: I will try to respond to you reasonably. If you want to exit, type bye.\n",
            "User: hello\n",
            "MovieExpert: hey\n",
            "User: batman\n",
            "MovieExpert: --Let\n",
            "User: what do you think about batman movie\n",
            "MovieExpert: Great, with the occasional stabs of shame.\n",
            "User: What action movie have you seen recently\n",
            "MovieExpert: The only thing I think I'd die for</b\n",
            "User: what happen in superman\n",
            "MovieExpert: I can just picture that, a cute girl like you following slip-and-fall and whiplash cheaters.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlfurXmH7l3H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llIQLBUc7l3H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gFm36ZE7l3I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbhQ7tCp7l3I"
      },
      "source": [
        "# tokens = []\n",
        "# lemma = []\n",
        "# #pos = []\n",
        "\n",
        "# for doc in nlp.pipe(df1['dialogs'].astype('unicode').values, batch_size=50,\n",
        "#                         n_threads=3):\n",
        "#     if doc.is_parsed:\n",
        "#         tokens.append([n.text for n in doc])\n",
        "#         lemma.append([n.lemma_ for n in doc])\n",
        "# #        pos.append([n.pos_ for n in doc])\n",
        "        \n",
        "#     else:\n",
        "#         # We want to make sure that the lists of parsed results have the\n",
        "#         # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
        "#         tokens.append(None)\n",
        "#         lemma.append(None)\n",
        "# #        pos.append(None)\n",
        "\n",
        "# df1['tokens'] = tokens\n",
        "# df1['lemma'] = lemma\n",
        "# #df1['pos'] = pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRjjfAIR7l3I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygLz53GW7l3I"
      },
      "source": [
        "## Now we can create our own chatbot and train it using Persuasion:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiyACjWn7l3I"
      },
      "source": [
        "# Create a chatbot\n",
        "c.\n",
        "hatbot = ChatBot('Persuasion')\n",
        "# This is to remove the accumulated knowledge base\n",
        "chatbot.storage.drop()\n",
        "\n",
        "# Create a new trainer for the chatbot\n",
        "trainer = ListTrainer(chatbot)\n",
        "\n",
        "# Train the chatbot based on Persuasion\n",
        "trainer.train(persuasion_sents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbeItrAC7l3I"
      },
      "source": [
        "## Next, run the chatbot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhla4tdz7l3J"
      },
      "source": [
        "print(\"Persuasion: I will try to respond to you reasonably. If you want to exit, type bye.\")\n",
        "\n",
        "# Below is the chatting\n",
        "while True:\n",
        "    \n",
        "    user_input = input(\"User: \")\n",
        "    user_input=user_input.lower()\n",
        "    \n",
        "    if(user_input!='bye'):\n",
        "        if(user_input == 'thanks' or user_input == 'thank you'):\n",
        "            break\n",
        "            print(\"Persuasion: You're welcome.\")\n",
        "        else:\n",
        "            if(greeting(user_input) != None):\n",
        "                print(\"Persuasion: \" + greeting(user_input))\n",
        "            else:\n",
        "                print(\"Persuasion: \", end = \"\")\n",
        "                print(chatbot.get_response(user_input))\n",
        "    else:\n",
        "        print(\"Persuasion: Bye! It was a great chat.\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}